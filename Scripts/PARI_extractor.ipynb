{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<---Code to extract all text articles in all languages--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import html5lib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<--- https://ruralindiaonline.org/articles/?lang=hi&&page=2 (Page link format )--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base url ,url of base page articles and actual article url -> for reference\n",
    "\n",
    "base_url =\"https://ruralindiaonline.org\"\n",
    "article_url = \"https://ruralindiaonline.org/articles/?lang=hi&&page=2\"\n",
    "article_page_url = \"https://ruralindiaonline.org/articles/%E0%A4%9C%E0%A4%B9%E0%A4%BE%E0%A4%81-%E0%A4%96%E0%A5%87%E0%A4%A4%E0%A5%80-%E0%A4%95%E0%A4%BE-%E0%A4%AE%E0%A4%A4%E0%A4%B2%E0%A4%AC-%E0%A4%B9%E0%A5%88-%E0%A4%A6%E0%A5%8B-%E0%A4%AA%E0%A5%82%E0%A4%B0%E0%A5%8D%E0%A4%A3%E0%A4%95%E0%A4%BE%E0%A4%B2%E0%A4%BF%E0%A4%95-%E0%A4%A8%E0%A5%8C%E0%A4%95%E0%A4%B0%E0%A4%BF%E0%A4%AF%E0%A4%BE%E0%A4%81-%E0%A4%95%E0%A4%B0%E0%A4%A8%E0%A4%BE/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to extract all article links from the current page\n",
    "\n",
    "def get_page_articlelinks(article_url,base_url):\n",
    "    r = requests.get(article_url)\n",
    "    article_links=[]\n",
    "    soup = BeautifulSoup(r.content, 'html.parser') \n",
    "    snippet=soup.find_all('h3')\n",
    "    for h3 in snippet:\n",
    "        for link in h3.find_all('a'):\n",
    "            article_links.append(base_url+link.get('href'))\n",
    "    return article_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to get all article links for the language specified and the number of pages\n",
    "\n",
    "def get_all_articlelinks(lang,no_of_pages,base_url):\n",
    "    all_articlelinks =[]\n",
    "    for i in range(2,no_of_pages):\n",
    "        article_page_url = \"https://ruralindiaonline.org/articles/?lang=\"+lang+\"&&page=\"+str(i)\n",
    "        # Calling get_page_articlelinks to list all articles on that page\n",
    "        article_links = get_page_articlelinks(article_page_url,base_url)\n",
    "        all_articlelinks.extend(article_links)\n",
    "    return all_articlelinks\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to get article body text \n",
    "\n",
    "def get_article_body(article_link):\n",
    "    hindi_text =\"\"\n",
    "    r = requests.get(article_link)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser') \n",
    "    snippet=soup.findAll(\"div\", {\"class\": \"rich-text\"})\n",
    "    snippet_next = soup.findAll(\"div\", {\"class\": \"paragraph-block text-align-default content\"})\n",
    "    for x in snippet:\n",
    "        hindi_text += x.text+\" \"\n",
    "    for x in snippet_next:\n",
    "        hindi_text += x.text+\" \"\n",
    "    new_str = hindi_text.replace(\"\\n\", \" \")\n",
    "    return new_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all links for a particular language\n",
    "\n",
    "all_links = get_all_articlelinks('or',52,base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the body of all articles and keep them in seperate text files inside a folder\n",
    "\n",
    "import os\n",
    "\n",
    "path = \"/home/ankita/CLAP/PARI/Odia/\" # Change this as per language\n",
    "# reset the below value in case of connection error\n",
    "file_counter = 0\n",
    "\n",
    "# To be used in cases when there is a connection error in between , to continue where we left off\n",
    "links =all_links[0:] \n",
    "\n",
    "for link in links: \n",
    "    file = open(path+\"article\"+str(file_counter)+\".txt\", \"w\")\n",
    "    file.write(get_article_body(link))\n",
    "    file.close()\n",
    "    file_counter +=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
