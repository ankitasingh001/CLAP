{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <--- The code outputs stastistical data after cleaning the files and converting it into tasks--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "import glob\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "from operator import add\n",
    "from pathlib import Path\n",
    "import indicnlp\n",
    "import codecs\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining minimum/ maximum lengths for all languages\n",
    "\n",
    "MIN_MAR = 4\n",
    "MAX_MAR = 10\n",
    "\n",
    "MIN_TEL =4\n",
    "MAX_TEL =10\n",
    "\n",
    "MIN_TAM = 3\n",
    "MAX_TAM = 10\n",
    "\n",
    "MIN_MAL = 3\n",
    "MAX_MAL = 10\n",
    "\n",
    "MIN_OTH =4\n",
    "MAX_OTH =10\n",
    "\n",
    "waste_len =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the min,max length for the language passed\n",
    "\n",
    "def get_len(language):\n",
    "    if language==\"Marathi\" or language == \"Hindi\":\n",
    "        return MIN_MAR,MAX_MAR\n",
    "    elif language==\"Telugu\":\n",
    "        return MIN_TEL,MAX_TEL\n",
    "    elif language ==\"Tamil\":\n",
    "        return MIN_TAM,MAX_TAM\n",
    "    elif language ==\"Malayalam\":\n",
    "        return MIN_MAL,MAX_MAL\n",
    "    else :\n",
    "        return MIN_OTH,MAX_OTH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide two numbers\n",
    "\n",
    "def div(x,y):\n",
    "    try:\n",
    "        return x/y\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate csv file from observed data\n",
    "\n",
    "def write_list_to_file(guest_list, filename):\n",
    "    with open(filename,'a') as outfile:\n",
    "        wr = csv.writer(outfile, dialect='excel')\n",
    "        wr.writerow(guest_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing special characters check in the string passed\n",
    "\n",
    "def checks(string):\n",
    "    regex = '-'\n",
    "    regex1 = '[A-Za-z]+'\n",
    "    regex2 = '/'\n",
    "    regex3 = '\\/'\n",
    "\t\t\n",
    "    unwanted_symbols = ['/', '-', '[', '\\\\', ']', '॥', '।' ,'<', '>', '”', '“', '*', '*']\n",
    "    if string == \"\":\n",
    "        return False\n",
    "    for symbol in unwanted_symbols:\n",
    "        if string.find(symbol) != -1:\n",
    "            return False\n",
    "        if re.match(regex, string):\n",
    "            return False\t\t\n",
    "        if re.match(regex2, string):\n",
    "            return False\n",
    "        if re.match(regex3, string):\n",
    "            return False\n",
    "        if string.find(\"/\") != -1:\n",
    "            return False\n",
    "        if string.find('-') != -1:\n",
    "            return False\n",
    "        if string.find('[') != -1:\n",
    "            return False\n",
    "        if string.find(\"\\\\\") != -1:\n",
    "            return False\n",
    "        if string.find(']') != -1:\n",
    "            return False\n",
    "        if string.find('॥') != -1:\n",
    "            return False\n",
    "        if string.find('।') != -1:\n",
    "            return False\n",
    "        if string.find('<') != -1:\n",
    "            return False\n",
    "        if string.find('>') != -1:\n",
    "            return False\n",
    "        if string.find('”') != -1:\n",
    "            return False\n",
    "        if string.find('“') != -1:\n",
    "            return False\n",
    "        for ch in range(0,26):\n",
    "            if string.find(chr(65+ch)) != -1 or string.find(chr(97+ch)) != -1:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying filters on the passed sentences\n",
    "\n",
    "def make_textfile_object(sentences, min_length, max_length, task_type_dum, task_type, language, path , seperator):\n",
    "    f1 = open(path, \"w+\")\n",
    "    waste_len=0\n",
    "    filtered_sentences  = []\n",
    "    filtered_sentences_specialchar = []\n",
    "    filtered_sentences_length = []\n",
    "    for dat in sentences:\n",
    "        dat = dat.replace('\\xc2\\xa0', '')\n",
    "        dat = dat.replace('\\n', '')\n",
    "        dat = dat.replace('  ', '')\n",
    "        dat = dat.strip()\n",
    "        if task_type_dum == 'quote':\n",
    "             dat = dat.split('\"')[1]\n",
    "             dat = dat.strip()\n",
    "        elif task_type_dum == 'quote2':\n",
    "             dat = dat.split(\"'\")[1]\n",
    "             dat = dat.strip()\n",
    "        elif task_type_dum == 'diag':\n",
    "            dat = dat.split(':')[-1]\n",
    "            dat = dat.strip()\n",
    "        len_dat = len(dat.split(' '))\n",
    "        \n",
    "        if len_dat >= min_length and len_dat <= max_length and checks(dat)==True:\n",
    "            filtered_sentences.append(dat)\n",
    "            \n",
    "    for sent in filtered_sentences:\n",
    "        f1.write(sent)\n",
    "        f1.write(seperator)\n",
    "        #f1.write(u\"।\")\n",
    "        f1.write('\\n')\n",
    "\n",
    "    return len(filtered_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the name is a language\n",
    "\n",
    "def check_lang(lang):\n",
    "    if lang =='Hindi' or lang=='Bengali' or lang=='Odia' or lang=='Tamil' or lang =='Telugu' or lang == 'Marathi' or lang == 'Malayalam' or lang == 'Punjabi' or lang=='Gujrati' or lang=='Kannada':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperator for various languages\n",
    "\n",
    "def seperator(language):\n",
    "    if language =='Hindi' or language =='Bengali' or language=='Odia' or language =='Punjabi':\n",
    "        return u\"।\"\n",
    "    else: \n",
    "        return \".\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "match =0\n",
    "my_path = '/home/ankita/CLAP/Data'\n",
    "write_path = '/home/ankita/CLAP/Data_1/'\n",
    "csv_path =   '/home/ankita/CLAP/Data/summary.csv'\n",
    "regex = '[!|?|\\.|\\\"|\\'|\\*|\\-|\\[|\\]]'\n",
    "regex_dot = r'[^\\.!?]*[!\\?\\.]'\n",
    "regex_quote = r'[\\\"][^\\\"]*[\\\"]'\n",
    "regex_quote2 = r'[\\'][^\\']*[\\']'\n",
    "regex_colon = '[^\\.!?:]*[:][^\\.!?:]*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting required data from the given path, source and language\n",
    "\n",
    "def extract_data(my_path,language,source):\n",
    "    \n",
    "    # Create a path to write the files after filter\n",
    "    \n",
    "    filter_path = os.path.join(write_path, source, language)\n",
    "    if not os.path.isdir(filter_path):\n",
    "        os.makedirs(filter_path)\n",
    "    \n",
    "    #Initialise counters for each source and language\n",
    "    \n",
    "    total_tasks=0\n",
    "    total_filtertasks =0\n",
    "        \n",
    "    #Iterate through all text files for the source and language\n",
    "    \n",
    "    for file in Path(my_path).glob('**/*.txt'):\n",
    "        taskvalue =[]\n",
    "        textFile_str = str(file)\n",
    "        path_list = textFile_str.split(os.sep)\n",
    "        min_length,max_length = get_len(language)\n",
    "        textFile = open(textFile_str, 'rb')\t\n",
    "    \n",
    "        data = textFile.read()\n",
    "        data = data.decode('utf-8')\n",
    "        data = re.sub('[\\n0-9()]', ' ', data)\n",
    "        data = re.sub(' +', ' ',data)\n",
    "        data = re.sub('\\n+', '', data)\n",
    "        \n",
    "        textFile_str = textFile_str.split('/')[-1].split('.')[0]\n",
    "        filter_data_path = filter_path +\"/\"+textFile_str\n",
    "        \n",
    "        quote_data = re.findall(regex_quote, data)\n",
    "        quote_sen_len  = make_textfile_object(quote_data, min_length, max_length, \"quote\", \"Conversational\", language,filter_data_path, seperator(language))\n",
    "        data = re.sub(regex_quote, '' ,data)\n",
    "        \n",
    "        quote_data2 = re.findall(regex_quote2, data)\n",
    "        quote2_sen_len = make_textfile_object(quote_data2, min_length, max_length, \"quote2\",\"Conversational\", language,filter_data_path, seperator(language))\n",
    "        data = re.sub(regex_quote2, '' ,data)\n",
    "        \n",
    "        diag_data = re.findall(regex_colon, data)\n",
    "        diag_sen_len = make_textfile_object(diag_data, min_length, max_length, \"diag\",\"Dialouge\", language, filter_data_path, seperator(language))\n",
    "        data = re.sub(regex_colon, '' ,data)\n",
    "        \n",
    "        reg_data =data.split(seperator(language))\n",
    "        reg_sen_len = make_textfile_object(reg_data, min_length, max_length, \"regular\",\"Regular\", language, filter_data_path, seperator(language))\n",
    "        \n",
    "        total_data =len(quote_data)+len(quote_data2)+len(diag_data)+len(reg_data)\n",
    "        total_sen_len =quote_sen_len+quote2_sen_len+diag_sen_len+reg_sen_len\n",
    "        \n",
    "        total_tasks +=total_data\n",
    "        total_filtertasks +=total_sen_len\n",
    "    \n",
    "    return total_tasks,total_filtertasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data from all directory and dumping filtered data to a new directory following directory structure\n",
    "\n",
    "Data_source = [f.path for f in os.scandir(my_path) if f.is_dir()]\n",
    "\n",
    "for data_path in Data_source:\n",
    "    \n",
    "    source =data_path.split('/')[-1]\n",
    "    lang_for_source = [f.path for f in os.scandir(data_path) if f.is_dir()]\n",
    "    \n",
    "    for lang_path in lang_for_source:\n",
    "        \n",
    "        language =lang_path.split('/')[-1]        \n",
    "        if(check_lang(language) is False):\n",
    "            continue\n",
    "        total_tasks,total_filtertasks = extract_data(lang_path,language,source)\n",
    "        data_list = [source,language,total_tasks,total_filtertasks]\n",
    "        write_list_to_file(data_list,csv_path)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<---END OF CODE , further processing in  analyser part 2--->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
